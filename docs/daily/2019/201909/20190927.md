## 本日やったこと

1. Cuboidくん(仮)の要件定義
2. サーモグラフィーの調査
3. open-jtalkで音声合成
4. Google Cloud APIで音声認識
5. Emphath APIで音声感情認識

## Cuboidくん(仮)の要件定義

[資料を別のフォルダ](../../quadrilatere/README.md)に格納する。\
仮名Cuboid-petit

### Cuboidくんとの差別化

* サイズを150[mm]に抑え、狭いスペースに入り込むことが可能
* センサを追加しできることを増やす
    * 現時点ではサーモグラフィーを搭載
    * のちのちには心拍数とか脳波とりたい
        * 人やモータの発熱異常などの検知
* 執務室の見回りをして人の状態を取りたい
* コミュニケーションができるようにしたい
    * おいでって言ったらくるとか
    * 名前を覚えるとか
* IFTTT/GASなどを使って他のIoTデバイスやSlack/Googleカレンダー等と連携をしたい
    * 会議の前になったらアナウンスするだとか
    * 役に立ちそうなアプリを作りたい

### 必要な要素技術

#### ハード設計

* CPU・センサの選定
* 材料調達・発注
* 組み立て
* 回路設計
* Inventor(?)でCAD作成
* URDFの作成

#### ハード-ソフト設計

* モータードライバ
* カメラドライバ
* LiDAR
* サーモイメージャドライバ
* gmapping/navigation
* サーバとの通信
* サーバ開設

#### ソフト-アプリ設計

* Webアプリ,POCレベルの何か
* 連携
    * GAS
    * webhook
    * Slack
    * Google カレンダー
* 通信・認証関連
    * Oath
    * Websocket/WebRTC
* 音声合成・音声認識
    * Google Cloud Speech API(音声認識)
    * Empath(音声感情認識)
    * open-jtalk(音声合成)
* 画像認識
    * 顔認識
    * 人体認識
    * 表情認識
    * 目線認識

---

## サーモグラフィーの調査

人の体温を取るためにサーモイメージャをCuboid-petitに搭載することを考える。\
利用用途例として、執務室内を巡回し、人の発熱を検知してアラームを鳴らすことを考える。

### 体温に関しての調査

体表温度から体温を推定するには両者の関連を知る必要がある。\
また体表温度は環境温度によって変化するため、体表温度と環境温度の関連を知る必要がある。

#### 体温、体表温度、環境温度の関係

[NEC技法](https://jpn.nec.com/techrep/journal/g10/n03/pdf/100312.pdf)から両方の関係調査したことをまとめる。
* 人が環境温度に慣れる時間を15分とること
* 環境温度25度のとき、体温が36.4度とすると顔正面の体表温度は34.8度
* 環境温度が上がるに連れて体内温度との差が小さくなっていく
* 環境温度が20~25度で安定していれば設定値を体温より1.6度低い値にすれば良い

#### 人間の体温の周期

人間の体温は個人差が大きく、平均36.4~37.0度とされている。\
体温が異なる要因として、年齢、性別、食事、睡眠、生理周期などが挙げられる。\
また、体温は一日を通しても上下し夕方頃が最も高いとされている。\
このことから個人の時間ごとの平熱を測定し、普段より1.0度高ければ熱の判定を行うことが理想である。\
今回は、サーモグラフィの精度や個人情報の観点から38度以上を熱として判定する。\
環境温度を25度としたときに、サーモイメージャで36.4度以上あれば発熱があると判定する。


### ハード選定

#### 求めるスペック

最低限
* 解像度
* 30FPS
* 精度プラスマイナス１度
* 機体の中に収まるサイズ
* USB接続でLinuxとの通信可能

望ましい
* 解像度640*480
* 60FPS
* 精度プラスマイナス0.1度(0.5度)
* ROSパッケージが存在する
* RGBカメラ付属

### SeeK Compact
[SeeK Compact](http://www.ned-sensor.co.jp/products/thermal_camera/seek-compact)
は小型で低価格のカメラである。
* 解像度206*156
* 温度ベース画像32*136ピクセル
* フレームレート8Hz
* 5万円以下
* カルコゲナイドレンズ4mm
* 画角36度
* 精度不明
* ROSパッケージ有り[seekthermal_ros](https://github.com/ethz-asl/seekthermal_ros)

足りないけど試してみても良いかも？

---

## open-jtalkで音声合成

open-jtalkを試してみた。
サウンドカード認識されなくて時間がかかった。
### 開発環境
* Python3-5-2
### git-hub
### インポートして使ってみる

---

## Google Cloud APIで音声認識

音声認識を試してみた。コードを貼る。

### Google Cloud APIの設定
* プロジェクト作成
* APIの有効化
* API Keyの設定
#### Pythonプログラムの作成
コマンドは```Python stt2.py```
```
#coding:utf8
import base64
from googleapiclient import discovery
import httplib2
 
#APIキーを設定
key = "---------------------------------"
 
#音声認識に使うファイル名
speech_file = "test.wav"
 
#URL情報
DISCOVERY_URL = ('https://{api}.googleapis.com/$discovery/rest?'
                 'version={apiVersion}')
 
#APIの情報を返す関数
def get_speech_service():
    http = httplib2.Http()
    return discovery.build(
        'speech', 'v1', http=http, discoveryServiceUrl=DISCOVERY_URL, developerKey=key)
 
 
#音声ファイルを開く
with open(speech_file, 'rb') as speech:
    speech_content = base64.b64encode(speech.read()) 
 
#APIの情報を取得して、音声認識を行う
service = get_speech_service()
service_request = service.speech().recognize(
    body={
        'config': {
            'encoding': 'LINEAR16',
            'sampleRateHertz': 48000,
            'languageCode': 'ja-JP', #日本語に設定
            'enableWordTimeOffsets': 'false',
        },
        'audio': {
            'content': speech_content.decode('UTF-8')
            }
        })
 
#SpeechAPIによる認識結果を保存
response = service_request.execute()
 
#見やすいようにコンソール画面で出力
for i in response["results"]:
    print(i["alternatives"][0]["transcript"],"confidence:" , i["alternatives"][0]["confidence"])

```
---
## Emphath APIで音声感情認識
### 概要
### 登録方法
### プログラム
```
!#/bin/sh

curl=`cat <<EOS
curl
    -F apikey=-------------------------------------
    -F wav=@/home/gisen/test_11025.wav
    https://api.webempath.net/v2/analyzeWav
EOS`
eval ${curl}
```
---


[トップへ](#本日やったこと)

<!--
```
プログラムを書く
```
-->


